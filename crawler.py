import requests
import re
import time
import sys
import asyncio
import random
from typing import List, Dict, Optional
from playwright.sync_api import sync_playwright

# [ì¤‘ìš”] Windows í™˜ê²½ì—ì„œ Streamlit + Playwright ì‚¬ìš© ì‹œ ë°œìƒí•˜ëŠ” asyncio ì¶©ëŒ í•´ê²°
if sys.platform.startswith("win"):
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

def get_place_id(url: str) -> Optional[str]:
    """
    ì…ë ¥ëœ URL(ë‹¨ì¶• URL í¬í•¨)ì„ ë¶„ì„í•˜ì—¬ ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤ ê³ ìœ  IDë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    ]
    headers = {"User-Agent": random.choice(user_agents)}
    
    try:
        print(f"ğŸ” URL ë¶„ì„ ì¤‘: {url}")
        response = requests.get(url, headers=headers, allow_redirects=True)
        final_url = response.url
        print(f"ğŸ“ ìµœì¢… URL: {final_url}")

        match = re.search(r'/(place|restaurant|hospital|hair|accommodations|campsite)/(\d+)', final_url)
        if match: return match.group(2)
        
        match = re.search(r'[?&]id=(\d+)', final_url)
        if match: return match.group(1)

        if "place" in final_url:
            id_match = re.search(r'"id":"(\d+)"', response.text)
            if id_match: return id_match.group(1)

    except Exception as e:
        print(f"âŒ ID ì¶”ì¶œ ì‹¤íŒ¨: {e}")
    
    return None

def crawl_naver_reviews(place_id: str, max_count: int = 50) -> List[Dict]:
    """
    í”Œë ˆì´ìŠ¤ IDë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëª¨ë°”ì¼ ë¦¬ë·° í˜ì´ì§€ì— ì§ì ‘ ì ‘ì†í•˜ì—¬ ë¦¬ë·°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.
    Target URL: https://m.place.naver.com/place/{place_id}/review/visitor
    """
    reviews = []
    target_url = f"https://m.place.naver.com/place/{place_id}/review/visitor"
    
    print(f"ğŸš€ í¬ë¡¤ë§ ì‹œì‘ (Target): {target_url}")

    with sync_playwright() as p:
        browser = p.chromium.launch(
            headless=False, 
            args=["--disable-blink-features=AutomationControlled"]
        )
        
        mobile_uas = [
            "Mozilla/5.0 (Linux; Android 10; SM-G981B) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.162 Mobile Safari/537.36",
            "Mozilla/5.0 (iPhone; CPU iPhone OS 13_2_3 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.0.3 Mobile/15E148 Safari/604.1"
        ]
        
        context = browser.new_context(
            user_agent=random.choice(mobile_uas),
            viewport={"width": 412, "height": 915},
            locale="ko-KR",
            timezone_id="Asia/Seoul"
        )
        page = context.new_page()

        try:
            page.goto(target_url, wait_until="domcontentloaded")
            time.sleep(random.uniform(3, 5))

            if "ì´ìš©ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤" in page.content():
                print("ğŸš« ì—¬ì „íˆ ì°¨ë‹¨ëœ ìƒíƒœì…ë‹ˆë‹¤.")
                return []

            # 0. 'ë°©ë¬¸ì ë¦¬ë·°' íƒ­ ëª…ì‹œì  í´ë¦­
            try:
                visitor_tab = page.locator("a, span").filter(has_text="ë°©ë¬¸ì ë¦¬ë·°").first
                if visitor_tab.is_visible():
                    visitor_tab.click()
                    print("âœ… 'ë°©ë¬¸ì ë¦¬ë·°' íƒ­ í´ë¦­")
                    time.sleep(random.uniform(1, 2))
            except:
                pass

            # 1. 'ìµœì‹ ìˆœ' ì •ë ¬ í´ë¦­
            try:
                sort_btn = page.get_by_text("ìµœì‹ ìˆœ")
                if sort_btn.count() > 0:
                    sort_btn.first.click()
                    print("âœ… 'ìµœì‹ ìˆœ' ì •ë ¬ í´ë¦­")
                    time.sleep(random.uniform(1, 2))
            except:
                pass

            # 2. 'ë”ë³´ê¸°' ë²„íŠ¼ ë°˜ë³µ í´ë¦­
            print("ğŸ“œ ë¦¬ë·° ëª©ë¡ í™•ì¥ ì¤‘...")
            scroll_limit = 2 if max_count <= 10 else 5
            
            for _ in range(scroll_limit): 
                try:
                    prev_height = page.evaluate("document.body.scrollHeight")
                    
                    more_btn = page.locator("a").filter(has_text="ë”ë³´ê¸°").first
                    if more_btn.is_visible():
                        more_btn.click()
                        time.sleep(random.uniform(2, 3))
                    else:
                        page.mouse.wheel(0, random.randint(500, 1000))
                        time.sleep(random.uniform(1, 2))
                        
                    curr_height = page.evaluate("document.body.scrollHeight")
                    if curr_height == prev_height:
                        break
                except Exception:
                    break
            
            # 3. 'ë‚´ìš© ë”ë³´ê¸°' í¼ì¹˜ê¸°
            try:
                expand_btns = page.locator("span, a").filter(has_text="ë‚´ìš© ë”ë³´ê¸°").all()
                if expand_btns:
                    print(f"ğŸ” ê¸´ ë¦¬ë·° {len(expand_btns)}ê°œ í¼ì¹˜ê¸°...")
                    for btn in expand_btns:
                        if btn.is_visible():
                            try:
                                btn.click()
                                time.sleep(random.uniform(0.5, 1.0))
                            except:
                                pass
            except:
                pass

            # 4. ë°ì´í„° ì¶”ì¶œ (í•„í„°ë§ ëŒ€í­ ê°•í™”)
            print("ğŸ“ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ì •ì œ ì¤‘...")
            
            elements = page.locator("span, div, a").all()
            
            collected_count = 0
            seen_texts = set()
            
            # [ì œì™¸ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸]
            # 1. UI ë° ì‹œìŠ¤í…œ ë¬¸êµ¬
            ui_keywords = [
                "ì˜ìˆ˜ì¦", "ì£¼ë¬¸", "ê¸¸ì°¾ê¸°", "ê³µìœ ", "ì‹ ê³ ", "ì—…ì²´", "ì†Œì‹", "ì´ìš©ì´ ì œí•œë˜ì—ˆìŠµë‹ˆë‹¤",
                "ì•Œë¦¼ë°›ê¸°", "ì´ë¯¸ì§€ ê°¯ìˆ˜", "ë°©ë¬¸ì ë¦¬ë·°", "ë¸”ë¡œê·¸ ë¦¬ë·°", "ì •ë ¬ ì•ˆë‚´", "ì¶”ì²œìˆœ", "ìµœì‹ ìˆœ",
                "í”¼ë“œí˜•ì‹", "ë¦¬ìŠ¤íŠ¸í˜•ì‹", "ë³„ê±´ ì—†ëŠ”ë°", "ë‹˜ì˜ ë¸”ë¡œê·¸", "ë§›ë³¼ìˆ˜ìˆëŠ”", "ë°ì´íŠ¸", "ë§›ì§‘",
                "ë¦¬ë·° í´ë Œì§•", "ë‹¤ë…€ì˜¤ì…¨ë‚˜ìš”", "ê²½í—˜ì„", "íŒ”ë¡œìš°", "ê°œì˜ ë¦¬ë·°ê°€ ë” ìˆìŠµë‹ˆë‹¤", "í¼ì³ë³´ê¸°"
            ]
            
            # 2. í‚¤ì›Œë“œ ë¦¬ë·° (í†µê³„) ë¬¸êµ¬ - ë„¤ì´ë²„ ê³ ì • ë¬¸êµ¬ë“¤
            keyword_reviews = [
                "ì´ëŸ° ì ì´ ì¢‹ì•˜ì–´ìš”", "ìŒì‹ì´ ë§›ìˆì–´ìš”", "ì¹œì ˆí•´ìš”", "ì¬ë£Œê°€ ì‹ ì„ í•´ìš”", "ë§¤ì¥ì´ ì²­ê²°í•´ìš”",
                "íŠ¹ë³„í•œ ë©”ë‰´ê°€ ìˆì–´ìš”", "ê°€ì„±ë¹„ê°€ ì¢‹ì•„ìš”", "ì–‘ì´ ë§ì•„ìš”", "ì¸í…Œë¦¬ì–´ê°€ ë©‹ì ¸ìš”", "ë·°ê°€ ì¢‹ì•„ìš”",
                "í˜¼ë°¥í•˜ê¸° ì¢‹ì•„ìš”", "ë‹¨ì²´ëª¨ì„ í•˜ê¸° ì¢‹ì•„ìš”", "ì£¼ì°¨í•˜ê¸° í¸í•´ìš”", "í™”ì¥ì‹¤ì´ ê¹¨ë—í•´ìš”", "íŠ¹ë³„í•œ ë‚  ê°€ê¸° ì¢‹ì•„ìš”"
            ]
            
            # 3. ë°©ë¬¸ ì¸ì¦ ì •ë³´
            visit_info = ["ë°©ë¬¸ì¼", "ì˜ˆì•½", "ëŒ€ê¸° ì‹œê°„", "ëª©ì ", "ë™í–‰", "ì•ˆë‚´", "ë©”ë‰´"]

            skip_keywords = ui_keywords + keyword_reviews + visit_info
            
            for el in elements:
                if collected_count >= max_count:
                    break
                
                try:
                    if not el.is_visible(): continue
                    
                    text = el.inner_text().strip()
                    text = text.strip('"').strip("'")
                    
                    # 1. ê¸¸ì´ í•„í„°ë§ (ë„ˆë¬´ ì§§ì€ í…ìŠ¤íŠ¸ ì œì™¸)
                    if len(text) < 15: continue
                    
                    # 2. ì¤‘ë³µ ì œê±°
                    if text in seen_texts: continue
                    seen_texts.add(text)
                    
                    # 3. í‚¤ì›Œë“œ í•„í„°ë§
                    if any(k in text for k in skip_keywords): continue
                    
                    # 4. ë¸”ë¡œê·¸ ì œëª© íŒ¨í„´ ì œì™¸ ([...])
                    if text.startswith("[") and text.endswith("]"): continue
                    
                    # 5. ë‚ ì§œ í˜•ì‹ ì œì™¸
                    if re.match(r'^\d{2}\.\d{2}\.\d{2}', text): continue
                    if re.match(r'^\d{4}ë…„', text): continue
                    
                    # 6. [í•µì‹¬] í†µê³„ ìˆ˜ì¹˜ íŒ¨í„´ ì œì™¸ (ì •ê·œì‹)
                    # ì˜ˆ: 5,132íšŒ, 4,980ëª… ì°¸ì—¬, +4, 12ì‚¬ì§„
                    if re.search(r'\d{1,3}(,\d{3})*[íšŒëª…ì›ê°œ]', text): continue # 5,132íšŒ, 10ëª…
                    if re.search(r'ë¦¬ë·° \d+', text): continue # ë¦¬ë·° 12
                    if re.search(r'ì‚¬ì§„ \d+', text): continue # ì‚¬ì§„ 13
                    if re.search(r'\+\d+', text): continue # +4

                    # 7. í¬í•¨ ê´€ê³„ í™•ì¸ (ë” ê¸´ í…ìŠ¤íŠ¸ ì„ í˜¸)
                    is_duplicate = False
                    for r in reviews:
                        if text in r['content']: 
                            is_duplicate = True
                            break
                        if r['content'] in text: 
                            r['content'] = text
                            is_duplicate = True
                            break
                    
                    if is_duplicate: continue

                    print(f"âœ… ìˆ˜ì§‘ë¨ [{collected_count+1}]: {text[:30]}...")

                    reviews.append({
                        "id": collected_count + 1,
                        "content": text
                    })
                    collected_count += 1
                    
                except Exception:
                    continue

        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
        
        finally:
            browser.close()
            print(f"âœ… ìˆ˜ì§‘ ì™„ë£Œ: {len(reviews)}ê±´")

    return reviews

if __name__ == "__main__":
    pass
